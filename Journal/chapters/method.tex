\section{Methods}
\label{sec:method}

\begin{figure*}[tb]
\centering
\input{tikzfigures/encoder_L2}
% \missingfigure{Need a new figure that shows the connection between DBMs and
% shortcut networks. Also need a figure to compare the different shortcut
% connections (top-down and bottom-up).}

\caption{Pre-training and fine-tuning of a 7-layer convolutional encoder network
with shortcuts. Pre-training is performed on the input images using a stack of
convolutional RBMs. The pre-trained weights and bias terms are used to initialize
a convolutional encoder network, which is fine-tuned on pairs of input images,
$x^{(0)}$, and segmentations, $y^{(0)}$.}

\label{fig:network}
\end{figure*}

In this paper, the task of segmenting MS lesions is defined as finding a
function $s$ that maps multi-modal images $I$, e.g., $I = (I_\text{FLAIR},
I_\text{T1})$, to corresponding lesion masks $S$. Given a set of
training images $I_n$, $n \in \N$, and corresponding segmentations $S_n$, we
model finding an appropriate function for segmenting MS lesions as an
optimization problem of the following form
\begin{equation}
\hat{s} = \arg \min_{s \in \mathcal{S}} \sum_n E(S_n, s(I_n))
\label{eq:segprob}
\end{equation}
where $\mathcal{S}$ is the set of possible segmentation functions, and $E$ is an
error measure that calculates the dissimilarity between ground truth
segmentations and predicted segmentations.

\subsection{Model Architecture}

The set of possible segmentation functions is modeled by the convolutional
encoder network illustrated in Fig.~\ref{fig:network}. \todo[inline]{There are
gaps in the description and a general understanding of CNNs is required to fill
these gaps in order to be able to implement the CEN.}Our network is divided into
two pathways, the convolutional pathway and the deconvolutional pathway.
The convolutional pathway consists of alternating convolutional and pooling
layers. The input layer of the convolutional pathway is composed of the image
voxels $x^{(0)}_i(\vect{p})$, $i \in [1, C]$, where $i$ indexes the
modality or input channel, $C$ is the number of modalities or channels, and
$\vect{p} \in \N^3$ are the coordinates of a particular voxel. The convolutional
layers automatically learn a feature hierarchy from the input images. A
convolutional layer is a deterministic function of the following form
\begin{equation}
x^{(l)}_j = \max \Bigg(0, \sum_{i=1}\tilde{w}^{(l)}_{\text{c},ij}*x^{(l-1)}_i +
b^{(l)}_j\Bigg)
\end{equation}
where $l$ is the index of a convolutional layer, $x^{(l)}_j$, $j \in [1,F]$,
denotes the feature map corresponding to the trainable convolution filter
$w^{(l)}_{\text{c},ij}$, $F$ is the number of filters of the current layer,
$b^{(l)}_j$ are trainable bias terms, $*$ denotes valid convolution, and
$\tilde{w}$ denotes a flipped version of $w$. A convolutional layer is followed
by an average pooling layer that halves the number of units in each dimension.

The deconvolutional pathway consists of alternating unpooling layers and
deconvolutional layers with optional shortcut connections to the corresponding
convolutional layers. The first deconvolutional layer uses the extracted
features of the convolutional pathway to calculate abstract segmentation
features as follows
\begin{equation}
y^{(L-1)}_i = \max\Bigg(0, \sum_{j=1}w^{(L)}_{\text{d},ij}\circledast
y^{(L)}_j + c^{(L-1)}_{i}\Bigg)
\end{equation}
where $y^{(L)} = x^{(L)}$, $L$ denotes the number of layers of the convolutional
pathway, $w^{(L)}_{\text{d},ij}$ and $c^{(L-1)}_i$ are trainable parameters of
the deconvolutional layer, and $\circledast$ denotes full convolution. Subsequent
deconvolutional layers use the activations of the previous layer
and corresponding convolutional layer to calculate less abstract segmentation
features as follows
% \begin{multline}
% y^{(l)}_i = \max\Bigg(0, \sum_{j=1}\Big(w^{(l+1)}_{\text{d},ij}\circledast
% y^{(l+1)}_j\\
% + w^{(l+1)}_{\text{s},ij}\circledast x^{(l+1)}_j\Big) +
% c^{(l)}_i\Bigg)
% \end{multline}
\begin{multline}
y^{(l)}_i = \max\Bigg(0, 
\sum_{j=1}w^{(l+1)}_{\text{d},ij}\circledast y^{(l+1)}_j\\
+ \sum_{j=1} w^{(l+1)}_{\text{s},ij}\circledast x^{(l+1)}_j +
c^{(l)}_i\Bigg)
\end{multline}
where $l$ is the index of a deconvolutional layer with shortcuts, and
$w^{(l+1)}_{\text{s},ij}$ are the filter kernels connecting the activations of
the convolutional pathway with the activations of the deconvolutional pathway.
The last deconvolutional layer integrates the low-level features extracted by
the first convolutional layer with the high-level features from the previous
layer to calculate a probabilistic lesion mask as follows
\begin{equation}
y^{(0)}_1 = \sigm\Bigg(\sum_{j=1}\Big(w^{(1)}_{\text{d},1j}\circledast
y^{(1)}_j +
w^{(1)}_{\text{s},1j}\circledast x^{(1)}_j\Big) + c^{(0)}_1\Bigg)
\end{equation}
where $\sigm(z)$ denotes the sigmoid function defined as $\sigm(z) = (1 +
\exp(-z))^{-1}, z \in \R$. To obtain a binary lesion mask from the probabilistic
output of our model, we chose a fixed threshold such that the mean Dice
similarity coefficient is maximized on the training set.

\begin{comment}
The set of possible segmentation functions is modeled by the convolutional
encoder network illustrated in Fig.~\ref{fig:network}. Our network consists of
three layers: an input layer, a convolutional layer, and a deconvolutional
layer. The input layer is composed of the image voxels $x^{(1)}_i(\vect{p})$, $i
\in [1, C], C \in \N$, where $i$ indexes the modality, $C$ is the number of
modalities, and $\vect{p} \in \R^3$ are the coordinates of a particular voxel.
The convolutional layer automatically learns features from the input images. It
is a deterministic function of the following form
\begin{equation}
y^{(1)}_j = \max \left(0, \sum_{i=1}^{C}\tilde{w}^{(1)}_{ij}*x^{(1)}_i +
b^{(1)}_j\right)
\end{equation}
where $y^{(1)}_j, j \in [1, F], F \in \N$, denotes the feature map corresponding
to the trainable convolution filter $w^{(1)}_{ij}$, $F$ is the number of
filters, $b_j$ is a trainable bias term, $*$ denotes valid convolution, and
$\tilde{w}$ denotes a flipped version of $w$. The deconvolutional layer uses the
extracted features to calculate a probabilistic lesion mask as follows
\begin{equation}
y^{(2)} = \sigm\left(\sum_{j=1}^Fw^{(2)}_{j}\circledast x^{(2)}_j +
b^{(2)}\right)
\end{equation}
where $x^{(2)}_j = y^{(1)}_j$, $w^{(2)}_j$ and $b^{(2)}$ are trainable
parameters, $\circledast$ denotes full convolution, and $\sigm(z)$ denotes the
sigmoid function defined as $\sigm(z) = (1 + \exp(-z))^{-1}, z \in \R$. To
obtain a binary lesion mask from the probabilistic output of our model, we chose
a fixed threshold such that the mean Dice similarity coefficient is
maximized on the training set.
\end{comment}

% \begin{itemize}
% \item Parameters can be learned by minimizing the error $E$ on the training set
% \item Minimization requires calculation of gradient
% \item Derive the gradient, also with new notation, multiple layers and short
% cuts
% \end{itemize}

\subsection{Gradient Calculation}
The parameters of the model can be efficiently learned by minimizing the error
$E$ on the training set, which requires the calculation of the gradient of $E$
with respect to the model parameters. Typically, neural networks are trained by
minimizing the sum of squared differences (SSD)
\begin{equation}
% Error function
E = \frac{1}{2}\sum_{\vect{p}}\left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2.
\end{equation}
The partial derivatives of the error with respect to the model parameters can be
calculated using the delta rule and are given by 
% $\Delta w^{(l)}_{\text{d},ij} =
% \delta^{(l-1)}_{\text{d},i} * \tilde{y}^{(l)}_j$, $\Delta w^{(l)}_{\text{s},ij}
% = \delta^{(l-1)}_{\text{d},i} * \tilde{x}^{(l)}_j$, $\Delta
% w^{(l)}_{\text{c},ij} = x^{(l-1)}_i * \tilde{\delta}^{(l)}_{\text{c},j}$
\begin{align}
\label{eq:dEd}
% Deconvolutional filters
\frac{\partial E}{\partial w^{(l)}_{\text{d},ij}} &=
\delta^{(l-1)}_{\text{d},i} * \tilde{y}^{(l)}_j, &
% Deconvolutional bias
\frac{\partial E}{\partial c^{(l)}_i} &= \sum_{\vect{p}}
\delta^{(l)}_{\text{d},i}(\vect{p}) \\
\label{eq:dEs}
% Shortcut filters
\frac{\partial E}{\partial w^{(l)}_{\text{s},ij}}
 &= \delta^{(l-1)}_{\text{d},i} * \tilde{x}^{(l)}_j \\
 \label{eq:dEc}
% Convolutional filters
\frac{\partial E}{\partial w^{(l)}_{\text{c},ij}} 
&= x^{(l-1)}_i * \tilde{\delta}^{(l)}_{\text{c},j},&
% Convolutional bias
\frac{\partial E}{\partial b^{(l)}_i} &= \sum_{\vect{p}}
\delta^{(l)}_{\text{c},i}(\vect{p})
\end{align}
The deltas of the first layer can be calculated with
\begin{equation}
% Delta update
\delta^{(0)}_{\text{d},1} = \big(y^{(0)}_1 -S\big)y^{(0)}_1\big(1-y^{(0)}_1\big)
\label{eq:delta0}
\end{equation}
The derivatives of the error with respect to the other layers can be calculated
by applying the chain rule of partial derivatives and are given by
\begin{align}
\label{eq:deltad}
% Delta update of deconvolutional layer
\delta^{(l)}_{\text{d},j} &=
\big(\tilde{w}^{(l)}_{\text{d},ij}*\delta^{(l-1)}_{\text{d},i}\big)\I\big(y^{(l)}_j
> 0\big)\\
\label{eq:deltac}
% Delta update of convolutional layer
\delta^{(l)}_{\text{c},i} &=
\big(w^{(l+1)}_{\text{c},ij}\circledast\delta^{(l+1)}_{\text{c},j}\big)\I\big(x^{(l)}_i
> 0\big)
\end{align}
where $l$ is the index of a deconvolutional layer, and convolutional layer,
respectively, $\delta^{(L)}_{\text{c},i} = \delta^{(L)}_{\text{d},j}$, and
$\I(z)$ denotes the indicator function defined as $1$ if the predicate $z$ is
true and $0$ otherwise. If a layer participates in a shortcut connection,
$\delta^{(l)}_{\text{c},j}$ needs to be adjusted by propagating the error back
through the shortcut connection. In this case, $\delta^{(l)}_{\text{c},j}$ is
calculated by
\begin{equation}
% Delta update convolutional with shortcut
\delta^{(l)}_{\text{c},j} =
\big(\delta^{(l)}_{\text{c},j}{}'+
\tilde{w}^{(l)}_{\text{s},ij}*\delta^{(l-1)}_{\text{d},i}\big)\I\big(x^{(l)}_j
> 0\big)
\label{eq:deltas}
\end{equation}
where $\delta^{(l)}_{\text{c},j}{}'$ is the activation before taking the
shortcut into account.

% Introduce new objective function and it's gradient

The sum of squared differences is a good measure of classification accuracy, if
the two classes are fairly balanced. However, if one class contains vastly more
samples, as is the case for lesion segmentation, the error measure is dominated
by the majority class and consequently, the neural network would learn to
completely ignore the minority class. To overcome this problem, we use a
combination of sensitivity and specificity, which can be used together to
measure classification performance even for vastly unbalanced problems. More
precisely, the final error measure is a weighted sum of the mean squared
difference of the lesion voxels (sensitivity) and non-lesion voxels
(specificity), reformulated to be error terms:
\begin{multline} 
E = r\frac{\textstyle\sum_{\vect{p}} \left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2 S(\vect{p})}{\textstyle\sum_{\vect{p}} S(\vect{p})}
\\
 + (1-r)\frac{\textstyle\sum_{\vect{p}} \left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2 \big(1 - S(\vect{p})\big)}{%
\textstyle\sum_{\vect{p}}\big(1 - S(\vect{p})\big)}
\end{multline}
We formulate the sensitivity and specificity errors as squared errors in order
to yield smooth gradients, which makes the optimization more robust. The
sensitivity ratio $r$ can be used to assign different weights to the two terms.
Due to the large number of non-lesion voxels, weighting the specificity error
higher is important, but the algorithm is stable with respect to changes in $r$,
which largely affects the threshold used to binarize the probabilistic output.
In all our experiments, a sensitivity ratio between $0.10$ and $0.01$ yields
very similar results.

To train our model, we must compute the derivatives of the modified objective
function with respect to the model parameters. Equations
\ref{eq:dEd}--\ref{eq:dEc} and \ref{eq:deltad}--\ref{eq:deltas} are a
consequence of the chain rule and independent of the chosen similarity measure.
Hence, we only need to derive the update rule for $\delta^{(0)}_{\text{d},1}$.
With $\alpha = 2r (\sum_{\vect{p}}S(\vect{p}))^{-1}$ and $\beta = 2(1 -
r)(\sum_{\vect{p}}(1 - S(\vect{p})))^{-1}$, we can rewrite $E$ as
\begin{align}
% \nonumber
% E =& \frac{1}{2}\sum_{\vect{p}}\Big(S(\vect{p})-y^{(0)}_1(\vect{p})\Big)^2 
% \alpha S(\vect{p})\\
% &+\frac{1}{2}\sum_{\vect{p}}\Big(S(\vect{p})-y^{(0)}_1(\vect{p})\Big)^2
% \beta(1-S(\vect{p}))\\
E=& \frac{1}{2}\sum_{\vect{p}}\big(\alpha S(\vect{p}) +
\beta(1-S(\vect{p}))\big)\Big(S(\vect{p})-y^{(0)}_1(\vect{p})\Big)^2
\end{align}
%
Our objective function is similar to the SSD, with an additional multiplicative
term applied to the squared differences. The additional factor is constant with
respect to the model parameters. Consequently, $\delta^{(0)}_{\text{d},1}$ can
be derived analogously to the SSD case, and the new factor is simply carried
over:
\begin{equation} 
\delta^{(0)}_{\text{d},1} = \big(\alpha S + \beta (1 - S)\big)\big(y^{(0)}_1 -
S\big) y^{(0)}_1 \big(1 - y^{(0)}_1\big)
\end{equation}

% The update for $\delta^{(0)}_{\text{d},1}$ can be derived analogously to the SSD
% case, and is given by
% \begin{equation} 
% \delta^{(0)}_{\text{d},1} = \big(\alpha S + \beta (1 - S)\big)\big(y^{(0)}_1 -
% S\big) y^{(0)}_1 \big(1 - y^{(0)}_1\big)
% \end{equation}
% where $\alpha = 2r (\sum_{\vect{p}}S(\vect{p}))^{-1}$ and $\beta = 2(1 -
% r)(\sum_{\vect{p}}(1 - S(\vect{p})))^{-1}$.

\subsection{Training}
% Initialize training

At the beginning of the training procedure, we have to set the model parameters
to some initial values, which are then fine-tuning during training. The choice
of the initial parameters can have a big impact on the learned model. There are
two ways to initialize a new model: a) using random values drawn from some
random distribution, or b) using pre-training. Pre-training can be performed
layer by layer using a stack of convolutional restricted Boltzmann machines
(convRBMs) (see Figure~\ref{fig:network}), thereby avoiding the potential
problem and diminishing or exploding gradients [??]. The first convRBM is
trained on the input images without the need for labeled data. Subsequent
convRBMs are trained on the hidden activations of the previous convRBM. After
all convRBMs have been trained, the model parameters of, e.g., the first
convolutional and last deconvolutional layer of the CEN can be initialized as
follows
\begin{align}
w_{\text{c}}^{(1)} &= \hat{w}^{(1)}, &
w_{\text{d}}^{(1)} &= 0.5\hat{w}^{(1)}, &
w_{\text{s}}^{(1)} &= 0.5\hat{w}^{(1)} \\
b^{(1)} &= \hat{b}^{(1)}, &
c^{(0)} &= \hat{c}^{(1)},
\end{align}
where $\hat{w}^{(1)}$ are the filter weights, $\hat{b}^{(1)}$ are the hidden
bias terms, and $\hat{c}^{(1)}$ are the visible bias terms of the first convRBM,
respectively. Alternatively, the bias terms can be initialized with zero and the
filter weights are initialized using random values that are drawn from a
distribution such that the variance of the activations of the layer units
remains roughly the same throughout all layers. This can be achieved by drawing
samples from the normal distribution $\mathcal{N}(0, \sigma)$, where $\sigma =
\sqrt{2/N}$, and $N$ denotes the number of incoming connections for one unit.
The influence of the initialization strategy on the learned model is analyzed in
Section~??.

A major challenge for gradient-based optimization methods is the choice of an
appropriate learning rate. Classic stochastic gradient descent [??] uses a fixed
or decaying learning, which is the same for all parameters of the model. However,
the partial derivatives of parameters of different layers can vary substantially
in magnitude, which might require different learning rates for the parameters of
different layers. Many methods have been proposed to automatically chose an
individual learning rate for each parameter of the model. Most methods (e.g.,
AdaGrad [??], AdaDelta [??], RMSprop [??], and Adam [??]) collect information
about the variance of the partial derivatives over multiple iterations and use
this information to set an appropriate learning rate. Second-order methods, like
Hessian-free optimization [??], do not require a learning rate. Instead, a step
towards the minimum of a quadratic approximation of the error function (or a
semi positive definite approximation thereof) is performed in each iteration.
Calculation of one update is much more costly for second-order methods, but it
also performs much more progress and navigates valleys of ``pathological
curvature'' more efficiently, which reduces the number of epochs required to
train the model. For more details about the aforementioned methods, the reader
is referred to the relevant papers.
