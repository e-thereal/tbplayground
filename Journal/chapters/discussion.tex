\section{Discussion}

% We have introduced a new method for the automatic segmentation of MS lesions
% based on convolutional encoder networks. The joint training of the feature
% extraction and prediction layers with a novel objective function allows for the
% automatic learning of features that are tuned for a given combination of image
% types and a segmentation task with very unbalanced classes. 

% More practical then other methods. Fast, only less than a second, compared to
% 30 to 40 minutes required by competing methods. Trained model is relatively
% small compared to library-based methods such as RMNMS, which require to store
% the training for inference. Can be tuned for any combination of image
% modalities, scanner characteristics.

% TODO: Reduce false positives using post-processing

The automatic segmentation of MS lesions is a very challenging task due to the
large variability in lesion size, shape, intensity, and location, as well as the
large variability of imaging contrasts produced by different scanners used in
multi-center studies. Most unsupervised methods model lesions as an outlier
class or a separate cluster in a subject-specific model, which makes them inherently
robust to inter-subject and inter-scanner variability. However, outliers are
often not specific to lesions and can also be caused by intensity
inhomogeneities, partial volume, imaging artifacts, and small anatomical structures such as blood
vessels, which leads to the generation of false positives. On the other hand,
supervised methods can learn to discriminate between lesion and non-lesion
tissue, but are more sensitive to the variability in lesion appearance and
different contrasts produced by different scanners. To overcome those
challenges, supervised methods require large data sets that span the variability
in lesion appearance and careful pre-processing to match the imaging contrast of new
images with those of the training set. Library-based approaches have shown great
promise for the segmentation of MS lesions, but do not scale well to very large
data sets due to the large amount of memory required to store comprehensive
sample libraries and the time required to scan such libraries for matching
patches. On the other hand, parametric deep learning models such as
convolutional neural networks scale much better to large training sets, because
the size required to store the model is independent of the training set size,
and the operations required for training and inference are inherently
parallelizable, which allows them to take advantage of very fast GPU-accelerated
computing hardware. Furthermore, the combination of many nonlinear processing
units allows them to learn features that are robust under large variability,
which is crucial for the segmentation of MS lesions.

Convolutional neural networks were originally designed to classify entire images
and designing networks that can segment images remains an important research
topic. Early approaches have formulated the segmentation problem as a patch-wise
classification problem, which allows them to directly use established
classification network architectures for image segmentation.
However, a major limitation of patch-based deep learning approaches is the time
required for training and inference. Fully convolutional networks can perform
the segmentation much more efficiently, but generally lack the precision to
perform voxel-accurate segmentation and cannot handle unbalanced classes.

To overcome these challenges, we have presented a new method for the automatic
segmentation of MS lesions based on deep convolutional encoder networks with
shortcut connections. The joint training of the feature extraction and
prediction pathways allows for the automatic learning of features at different
scales that are tuned for a given combination of image types and segmentation
task. Shortcuts between the two pathways allow high- and low-level features to
be leveraged at the same time for more consistent performance across scales. In
addition, we have proposed a new objective function based on the combination of
sensitivity and specificity, which makes the objective function inherently
robust to unbalanced classes such as MS lesions, which typically comprise less
than \SI{1}{\percent} of all image voxels.
We have evaluated our method on two publicly available data sets and a large
data set from an MS clinical trial, with the results showing that our method
performs comparable to the best state-of-the-art methods, even for relatively
small training set sizes. We have also shown that when a suitably large training
set is available, our method is able to segment MS more accurately than
widely-used competing methods such as EMS, LST-LGA, and Lesion-TOADS. The
substantial gains in accuracy were mostly due to an increase in lesion
sensitivity, especially for small lesions. Overall, the CEN with shortcuts
architecture performed consistently well over a wide range of lesion sizes.

Our segmentation framework is very flexible and can be easily extended. One such
extension could be to incorporate prior knowledge about the tissue type of each
non-lesion voxel into the segmentation procedure. The probabilities of each
tissue class could be precomputed by a standard segmentation method, after which
they can be added as an additional channel to the input units of the CEN, which
would allow the CEN to take advantage of intensity information from different
modalities and prior knowledge about each tissue class to carry out the
segmentation. In addition, our method can be applied to other segmentation
tasks. Although we have only focused on the segmentation of MS lesions in this
paper, our method does not make any assumptions specific to MS lesion
segmentation. The features required to carry out the segmentation are solely
learned from training data, which allows our method to be used to segment
different types of pathology or anatomy when a suitable training set is
available.

% Supervised challenges: large variability -> need good training data.
% Patch-based promising but doesn't scale well.
% Generally require good pre-processing
% Deep learning can overcome both challenges: highly non-linear -> robust
% feature learning, algorithms easily parallelizable, good for GPU
% implementation

\begin{comment}
The most significant limitation of the tested architecture is that very large
lesions can still extend beyond the receptive field of a particular voxel. This
reduces the network's ability to extract appearance features that would help the
identification of lesion voxels. For future work, we are planning to investigate
the use of deeper networks for increasing accuracy for very large lesions.
%
This work would require greater training times and a larger sample of scans with
high lesion loads, but we expect it to significantly improve the network's
ability to segment even very large lesions. In contrast to fully convolutional
networks and the u-net architecture, the size of the output segmentation of a
CEN is independent of the size of the receptive field, which allows us to design
networks that are able to learn features that cover large parts of the image, or
even global features that cover the entire image. Such features would be able to
estimate the global distribution of lesions and act as an automatically learned
lesion prior, further improving the robustness of our method.
\end{comment}
