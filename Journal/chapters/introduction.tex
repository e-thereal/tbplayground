\section{Introduction}

\IEEEPARstart{M}{ultiple}
sclerosis (MS) is an inflammatory and demyelinating disease of the central
nervous system with pathology that can be observed in vivo by magnetic resonance
imaging (MRI). MS is characterized by the formation of lesions, primarily
visible in the white matter on conventional MRI. Imaging biomarkers based on the
delineation of lesions, such as lesion load and lesion count, have established
their importance for assessing disease progression and treatment effect.
However, lesions vary greatly in size, shape, intensity and location, which
makes their automatic and accurate segmentation challenging.

% TODO: generative model was dictionary learning and sparse coding. Might extend
% clustering a little bit if need be.

% TODO: Add Lesion-TOADS summary

% TODO: state briefly what the problems with unsupervised methods are that would
% motivate use of supervised. Features are not specific to the problem. Features
% describe the majority of the image information and might not be representitive
% of small pathology like MS lesion that only compromise less than 1 percent of
% the image voxels.

Many automatic methods have been proposed for the segmentation of MS
\mbox{lesions} over the last two decades \cite{garcia2013review}, which can be
classified into unsupervised and supervised methods. Unsupervised methods do not
require a labeled data set for training. Instead, lesions are identified as an
outlier class using, e.g., clustering methods \cite{souplet2008} or generative
models \cite{weiss2013}. Current supervised approaches typically start with a
large set of features, either predefined by the user \cite{geremia2010} or gathered in a feature extraction
step such as by deep learning\cite{yoo2014}, which is followed by a separate
training step with labeled data to determine which set of features are the most
important for segmentation in the particular domain.
% For example, Yoo et al. \cite{yoo2014} proposed performing unsupervised learning
% of domain-specific features from image patches from unlabelled data using deep
% learning.
A recent breakthrough for automatic segmentation using deep learning comes from
the domain of cell membrane segmentation, in which Ciresan et al.
\cite{Ciresan2012} proposed to classify the centers of image patches directly
using a convolutional neural network (CNN) \cite{LeCun1998} without a dedicated
feature extraction step. Instead, features are learned indirectly within the
lower layers of the neural network during training, while the higher layers can
be regarded as performing the classification, which allows the learning of
features that are specifically tuned to the segmentation task. However, the time
required to train patch-based methods can make the approach infeasible when the
size and number of patches are large.

% TODO: can I add numerical values to it? Mostly my personal experience.

Recently, different CNN architectures
\cite{ronneberger2015,brosch2015,kang2014fully} have been proposed that are able
to feed through entire images, which removes the need to select representative
patches, eliminates redundant calculations where patches overlap, and therefore
scales up more efficiently with image resolution. Kang et al. introduced the
fully convolutional neural network (fCNN) for the segmentation of crowds in
surveillance videos \cite{kang2014fully}. However, fCNNs produce segmentations
of lower resolution than the input images due to the successive use of
convolutional and pooling layers, both of which reduce the dimensionality.
To predict segmentations of the same resolution as the input images, we recently
proposed using a 3-layer convolutional encoder network (CEN) \cite{brosch2015}
for MS lesion segmentation. The combination of convolutional \cite{LeCun1998}
and deconvolutional \cite{zeiler2011} layers allows our network to produce
segmentations that are of the same resolution as the input images. 

Another limitation of the traditional CNN is the trade-off between localization
accuracy, represented by lower-level features, and contextual information,
provided by higher-level features.
%
Ronneberger et al. \cite{ronneberger2015}
%
% found that increasing the depth of the
% CNN, and thereby increasing the size of the receptive field of a segmented voxel,
% increases the abstraction from the input data, which makes the segmentation
% method more robust to anatomical and intensity variations. They
%
proposed an 11-layer u-shaped network architecture called u-net,
% which leverages high-level and low-level features in order to predict
% segmentations that are both robust and accurate.
composed of a traditional contracting path (first half of the u), but augmented
with an expanding path (last half of the u), which replaces the pooling layers
of the contracting path with upsampling operations. To leverage both high- and
low-level features, shortcut connections are added between corresponding layers
of the two paths.
However,
% the successive application of convolutional, pooling, and
% unpooling layers reduces the size of the predicted segmentation by the size of
% the receptive field. This requires special handling of the border regions and
% limits the maximum size of the receptive field.
upsampling cannot fully compensate for the loss of resolution, and special
handling of the border regions is still required.

% Easier to apply than u-net because it does not need padding or cropping of the
% segmentation for training.
% 
% In this paper, we extend our previous framework to include more layers. Our
% model consists of two pathways, a convolutional pathway which consists of
% alternating convolutional and pooling layers and learns increasingly more
% abstract and robust features, and a deconvolutional pathway which consists of
% alternating deconvolutional and unpooling layers. In order for the segmentation
% to be driven by both low-level and high-level features, we introduce shortcut
% connections between layers of the two pathways. Similar to the u-net
% architecture, this allows the segmentation to be driven by both low-level and
% high-level features. In addition, the formalization of shortcut connections
% allows errors to be propagated through the shortcut connections, which in tern
% allows the learning of low-level features that are tuned for segmentation.

% Mention that we compared different architectures

We propose a new convolutional network architecture that combines the advantages
of a CEN \cite{brosch2015} and a u-net \cite{ronneberger2015}. Our network is
divided into two pathways, a traditional convolutional pathway, which consists
of alternating convolutional and pooling layers, and a deconvolutional pathway,
which consists of alternating deconvolutional and unpooling layers and predicts
the final segmentation. Similar to the u-net, we introduce shortcut connections
between layers of the two pathways. In contrast to the u-net, our network uses
deconvolution instead of upsampling in the expanding pathway and predicts
segmentations that have the same resolution as the input images and therefore
does not require special handling of the border regions. We have evaluated our
method on a large data set from an MS clinical trial and compared our results
with Lesion-TOADS \cite{shiee2010topology}, a widely used freely available
method for fully automatic lesion segmentation. Our results show that the CEN
approach is able to segment MS lesions more accurately than Lesions-TOADS, and
that our extended CEN architecture further improves segmentation accuracy
compared to our recently proposed 3-layer CEN.

% There has been a lot of interest in recent years in the machine learning
% community to develop better training methods for CNNs. However, training CNNs
% for medical image segmentation is particularly challenging due to the relatively
% small size of available training sets and the large size of 3D medical images,
% which only allows a few iterations to be used for training and hyperparameter
% tuning. Our second contribution is a comprehensive comparison of different first
% order and second order training method and parameter initialization strategies
% that can serve as a guideline for other researchers for training convolutional
% models for medical image segmentation.

% \item (Analysis of the relationship between regularization and training set
% size to avoid over- and underfitting)

% In this paper, we
% investigate the relationship between training set size and depth of the model on
% the segmentation performance and overfitting and compared the results to a the
% state-of-the-art lesion segmentation method lesion-TOADS, showing that network
% depth can improve segmentation performance for large data sets, but can also
% decrease the performance due to overfitting for smaller training sets, which
% makes network depth a tunable hyperparameter of the model. We've also
% investigated the influence of pre-training on the resulting model, showing that
% although the impact on the performance is minor, it has a big impact on the
% learned features.

% In this paper, we will build on our previous work. Although these networks have
% shown great potential, training of these networks can be difficult. The main
% contribution of this paper is a comprehensive comparison of different training
% strategies and algorithms that can serve as a guideline of how to design and
% train convolutional encoder networks. We have compared different first order and
% second order training methods and found the the right algorithm can have a major
% impact on the performance of the trained network. In addition, we evaluated the
% impact of pre-training and found that pre-training can significantly increase
% classification accuracy by preventing overfitting, if only small data sets are
% available. In addition, we evaluated the impact of the used objective function,
% comparing popular choices with our own objective function.

% We propose a new method for segmenting MS lesions that processes entire MRI
% volumes through a neural network with a novel objective function to
% automatically learn features tuned for lesion segmentation.
% Similar to fully convolutional networks \cite{kang2014fully}, our network
% processes entire volumes instead of patches, which removes the need to select
% representative patches, eliminates redundant calculations where patches overlap,
% and therefore scales up more efficiently with image resolution. This speeds up
% training and allows our model to take advantage of large data sets.
% Our neural network is 

% composed of three layers: an input layer composed of the
% image voxels of different modalities, a convolutional layer \cite{LeCun1998}
% that extracts features from the input layer at each voxel location, and a
% deconvolutional layer \cite{zeiler2011} that uses the extracted features to
% predict a lesion mask and thereby classify each voxel of the image in a single
% operation. The entire network is trained at the same time, which enables feature
% learning to be driven by segmentation performance. The proposed network is
% similar in architecture to a convolutional auto-encoder \cite{masci2011}, which
% produces a lower dimensional encoding of the input images and uses the decoder
% output to measure the reconstruction error needed for training, while our
% network uses the decoder to predict lesion masks of the input images. Due to the
% structural similarity to convolutional auto-encoders, we call our model a
% convolutional encoder network (CEN). Traditionally, neural networks are trained
% by back-propagating the sum of squared differences of the predicted and expected
% outputs. However, if one class is greatly underrepresented, as is the case for
% lesions, which typically comprise less than \SI{1}{\percent} of the image
% voxels, the algorithm would learn to ignore the minority class completely.
% To overcome this problem, we propose a new objective function based on a
% weighted combination of sensitivity and specificity, designed to deal with
% unbalanced classes and formulated to allow stable gradient computations.
