\section{Methods}
\label{sec:method}

In this paper, the task of segmenting MS lesions is defined as finding a
function $s$ that maps multi-modal images $I$, e.g., $I = (I_\text{FLAIR},
I_\text{T1}, I_\text{T2})$, to corresponding lesion masks $S$. Given a set of
training images $I_n$, $n \in \N$, and corresponding segmentations $S_n$, we
model finding an appropriate function for segmenting MS lesions as an
optimization problem of the following form
\begin{equation}
\hat{s} = \arg \min_{s \in \mathcal{S}} \sum_n E(S_n, s(I_n))
\label{eq:segprob}
\end{equation}
where $\mathcal{S}$ is the set of possible segmentation functions, and $E$ is an
error measure that calculates the dissimilarity between ground truth
segmentations and predicted segmentations.

% where $x^{(1)}_1 = I_\text{flair}$, $x^{(1)}_2 = I_\text{t1}$, $x^{(1)}_3 =
%  I_\text{t2}$, and $x^{(1)}_4 = I_\text{prior}$.

% \paragraph{Problem definition}
% \begin{itemize}
% 
% \item Given a set of multi-modal images $I_n = (I_{n, \text{flair}})$ and
% corresponding segmentations $S_n$, we define the task of finding an appropriate
% segmentation algorithm, as the task of finding a function $s$ that maps images
% to their segmentations, i.e. $S_n = s(I_n)$.
% 
% \item Segmentation is a function $s$ that maps an image $I$ to its segmentation
% $S$. That is $S = s(I)$.
% 
% \item Given a set of training images $I_i$ and corresponding segmentations
% $S_i$, we treat finding an appropriate function for segmenting T2 lesions as an
% optimization problem of the following form:
%  \begin{equation} 
% \hat{s} = \arg \max_{s \in \mathcal{S}} \sum_n \text{sim}(S_n, s(I_n)).
% \label{eq:segprob}
% \end{equation}
% where $\text{sim}$ denotes a function that calculates the similarity between
% ground truth segmentations and predicted segmentations, and $\mathcal{S}$ is the
% set of possible functions.
% \end{itemize}

\begin{figure}[tb]
\centering
\input{tikzfigures/encoder2}

\caption{Convolutional encoder network used to produce a lesion segmentation,
$S$, from multi-modal images, $I = (I_\text{FLAIR}, I_\text{T1}, I_\text{T2})$.
The first two layers form a convolutional neural network with trainable filter
kernels $w^{(1)}_{ij}$, and the last two layers form a deconvolutional neural
network with trainable filter kernels $w^{(2)}_j$.}

\label{fig:network}
\end{figure}

The set of possible segmentation functions is modeled by the convolutional
encoder network illustrated in Fig.~\ref{fig:network}. Our network consists of
three layers: an input layer, a convolutional layer, and a deconvolutional
layer. The input layer is composed of the image voxels $x^{(1)}_i(\vect{p})$, $i
\in [1, C], C \in \N$, where $i$ indexes the modality, $C$ is the number of
modalities, and $\vect{p} \in \R^3$ are the coordinates of a particular voxel.
The convolutional layer automatically learns features from the input images. It
is a deterministic function of the following form
\begin{equation}
y^{(1)}_j = \max \left(0, \sum_{i=1}^{C}\tilde{w}^{(1)}_{ij}*x^{(1)}_i +
b^{(1)}_j\right)
\end{equation}
where $y^{(1)}_j, j \in [1, F], F \in \N$, denotes the feature map corresponding
to the trainable convolution filter $w^{(1)}_{ij}$, $F$ is the number of
filters, $b_j$ is a trainable bias term, $*$ denotes valid convolution, and
$\tilde{w}$ denotes a flipped version of $w$. The deconvolutional layer uses the
extracted features to calculate a probabilistic lesion mask as follows
\begin{equation}
y^{(2)} = \sigm\left(\sum_{j=1}^Fw^{(2)}_{j}\circledast x^{(2)}_j +
b^{(2)}\right)
\end{equation}
where $x^{(2)}_j = y^{(1)}_j$, $w^{(2)}_j$ and $b^{(2)}$ are trainable
parameters, $\circledast$ denotes full convolution, and $\sigm(z)$ denotes the
sigmoid function defined as $\sigm(z) = (1 + \exp(-z))^{-1}, z \in \R$. To
obtain a binary lesion mask from the probabilistic output of our model, we chose
a fixed threshold such that the mean Dice similarity coefficient is
maximized on the training set.

The parameters of the model can be efficiently learned by minimizing the error
$E$ on the training set using stochastic gradient descent
\cite{LeCun1998}. Typically, neural networks are trained by minimizing the sum
of squared differences (SSD)
\begin{equation}
% Error function
E = \frac{1}{2}\sum_{\vect{p}}\left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2.
\end{equation}
The partial derivatives of the error with respect to the model parameters can be
calculated using the delta rule and are given by
\begin{align}
% Weight update
\frac{\partial E}{\partial w^{(2)}_j} &= \delta^{(2)} * \tilde{x}^{(2)}_j
\text{,} &
% Bias update
\frac{\partial E}{\partial b^{(2)}} &= \frac{1}{N^3}\sum_{\vect{p}}
\delta^{(2)}(\vect{p})
\label{eq:dE2}
% Convolutional model
\end{align}
with 
\begin{equation}
% Delta update
\delta^{(2)} = \big(y^{(2)} -S\big)y^{(2)}\big(1-y^{(2)}\big)
\label{eq:delta2}
\end{equation}
where $N^3$ is the number of voxels of a single input channel. The derivatives
of the error with respect to the first layer parameters can be calculated by
applying the chain rule of partial derivatives and is given by
\begin{align}
% Weight update
\frac{\partial E}{\partial w^{(1)}_{ij}} &= x^{(1)}_i * \tilde{\delta}^{(1)}_j,
&
% Bias update
\frac{\partial E}{\partial b^{(1)}_j} &= \frac{1}{M^3}\sum_{\vect{q}}
\delta^{(1)}_j(\vect{q})
\label{eq:dE1}
\end{align}
with
\begin{equation}
% Delta update
\delta^{(1)}_j = \big(w^{(2)}_{j}\circledast\delta^{(2)}\big)\I\big(y^{(1)}_j >
0\big)
\label{eq:delta1}
\end{equation}
where $M^3$ is the number of voxels of a feature map, $\vect{q} \in \R^3$, and
$\I(z)$ denotes the indicator function defined as $1$ if the predicate
$z$ is true and $0$ otherwise.

The sum of squared differences is a good measure of classification accuracy, if
the two classes are fairly balanced. However, if one class contains vastly more
samples, as is the case for lesion segmentation, the error measure is dominated
by the majority class and consequently, the neural network would learn to
completely ignore the minority class. To overcome this problem, we use a
combination of sensitivity and specificity, which can be used together to
measure classification performance even for vastly unbalanced problems. More
precisely, the final error measure is a weighted sum of the mean squared
difference of the lesion voxels (sensitivity) and non-lesion voxels
(specificity), reformulated to be error terms:
\begin{equation} 
E = r\frac{\textstyle\sum_{\vect{p}} \left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2 S(\vect{p})}{\textstyle\sum_{\vect{p}} S(\vect{p})}
  +
(1-r)\frac{\textstyle\sum_{\vect{p}} \left(S(\vect{p}) -
y^{(2)}(\vect{p})\right)^2 \big(1 - S(\vect{p})\big)}{%
\textstyle\sum_{\vect{p}}\big(1 - S(\vect{p})\big)}
\end{equation}
%where the first term captures the squared sensitivity error and the second term
%captures the squared specificity error.
We formulate the sensitivity and
specificity errors as squared errors in order to yield smooth gradients, which
makes the optimization more robust. The sensitivity ratio $r$ can be used to
assign different weights to the two terms. Due to the large number of non-lesion
voxels, weighting the specificity error higher is important, but the algorithm
is stable with respect to changes in $r$, which largely affects the threshold
used to binarize the probabilistic output. In all our experiments, a sensitivity
ratio between $0.10$ and $0.01$ yields very similar results.

To train our model, we must compute the derivatives of the modified
objective function with respect to the model parameters. Equations \eqref{eq:dE2},
\eqref{eq:dE1}, and \eqref{eq:delta1} are a consequence of the chain rule
%of derivatives
and independent of the chosen similarity measure.
%
The update for $\delta^{(2)}$ can be derived analogously to the SSD case,
and is given by
\begin{equation} 
\delta^{(2)} = \big(\alpha S + \beta (1 - S)\big)\big(y^{(2)} - S\big) y^{(2)}
\big(1 - y^{(2)}\big)
\end{equation}
where $\alpha = 2r (\sum_{\vect{p}}S(\vect{p}))^{-1}$ and $\beta = 2(1 -
r)(\sum_{\vect{p}}(1 - S(\vect{p})))^{-1}$.

% Hence, we only need to derive the update rule for $\delta^{(2)}$.
% With $\alpha = 2r (\sum_{\vect{p}}S(\vect{p}))^{-1}$ and $\beta = 2(1 -
% r)(\sum_{\vect{p}}(1 - S(\vect{p})))^{-1}$ we can rewrite $E$ as
% \begin{align}
% E &= \frac{1}{2}\sum_{\vect{p}} \left(S(\vect{p}) - y^{(2)}(\vect{p})\right)^2
% \alpha S(\vect{p}) +
% \frac{1}{2}\sum_{\vect{p}} \left(S(\vect{p}) - y^{(2)}(\vect{p})\right)^2
% \beta\big(1 - S(\vect{p})\big) \\
%  &= \frac{1}{2}\sum_{\vect{p}} \big(\alpha S(\vect{p}) +
%  \beta(1 - S(\vect{p}))\big)
%  \left(S(\vect{p}) - y^{(2)}(\vect{p})\right)^2
% \end{align}
% Our objective function is similar to the SSD, with an
% additional multiplicative term applied to the squared differences. The
% additional factor is constant with respect to the
% model parameters. Consequently, $\delta^{(2)}$ can be derived
% analogously to the SSD case, and the new factor is simply carried over:
% \begin{equation}
% \delta^{(2)} = \big(\alpha S + \beta (1 - S)\big)\big(y^{(2)} - S\big) y^{(2)}
% \big(1 - y^{(2)}\big)
% \end{equation}

% To account for the spatial distribution of lesions, we added a lesion
% distribution map as an additional channel to the input layer. Therefore, we
% affinely registered 250 subjects of an in-house data set from an MS clinical
% trial to MNI space and calculated the square root of the average lesion mask to
% counterbalance large differences in lesion probability between regions.