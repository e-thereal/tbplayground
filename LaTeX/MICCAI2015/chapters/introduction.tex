\section{Introduction}

Multiple sclerosis (MS) is an inflammatory and demyelinating disease of the
central nervous system with pathology that can be observed in vivo by magnetic
resonance imaging (MRI). MS is characterized by the formation of lesions,
primarily visible in the white matter on conventional MRI. Imaging biomarkers
based on lesion segmentations, such as lesion load and lesion count, have
established their importance to assess disease progression and treatment affect.
However, lesions vary greatly in shape, intensity and location, which makes
their automatic and accurate segmentation challenging.

% Manual or semi-automatic segmentation by expert users is a common way to
% determine the extent of MS lesions, which is a time-consuming task and can
% suffer from intra- and inter-rater variability. The automatic segmentation is an
% attractive alternative, but 

% \paragraph{Motivation}
% \begin{itemize}
%   \item MS is a neuro-degenerative disease of the central nervous system
%   characterized by the formation of lesions
%   \item Accurate, reproducible and automatic segmentation of
%   lesions is important to assess disease progression, treatment affect, lesion
%   LL an important end-point of clinical trials
% \end{itemize}

Many automatic methods have been proposed for the segmentation of MS lesions
over the last two decades. Most methods formalize lesion segmentation as a voxel
classification problem, where each voxel of an image is assigned one of the two
classes ``lesion voxel'' and ``non-lesion voxel''. The classification problem
itself can then be solved either in a supervised way using, e.g., artificial
neural networks \cite{zijdenbos1994} or random forests \cite{geremia2010}, or
unsupervised using clustering methods with one outlier class \cite{souplet2008}
or by treating lesions as an outlier of a generative model \cite{weiss2013}. A
variety of features have been proposed to drive the segmentation. Early
approaches have used the intensity values of different modalities at a
particular voxel location as the input features \cite{zijdenbos1994}. However,
simple intensity features can be sensitive to intensity variations between
images. Geremia et. al \cite{geremia2010} have shown that carefully chosen
context-rich features are more robust to intensity variations, which improves
segmentation accuracy. Instead of hand-designing features, Youngjin et. al
\cite{yoo2014} proposed to learn domain specific features from image patches
from an unlabelled data set using unsupervised feature learning. For the
automatic segmentation of cell membranes, Ciresan et. al proposed to classify
the center of image patches directly using a convolutional neural network
without a dedicated feature extraction step \cite{Ciresan2012}. Features are
learned indirectly within the lower layers of the neural network during
training, while the higher layers can be regarded as performing the
classification. In contrast to unsupervised feature learning, this approach
allows the learning of features that are specifically tuned to the segmentation
task. Although supervised and unsupervised feature learning methods have shown
great potential for image segmentation, the time required to train complex
patch-based feature extraction methods can make the approach infeasible when the
size and the number of patches is large. Ciresan et. al have reported a training
time of more than a week to train their patch-based segmentation model using 4
GPUs on 2D images with a resolution of \num{512x512} pixels
\cite{Ciresan2012}. To scale patch-based classification to 3D images with a
resolution of \num{256x256x50}, Youngjin et. al used only a small fraction
(\SI{0.1}{\percent}) of the possible patches for training, which might limit the
ability to learn features that are representative of the entire image.

% \paragraph{Related Work}
% 
% \begin{itemize}
% 
% \item Trend from simple intensity based features to more complex features
% extracted or learned from image patches.
%   
% \end{itemize}

In this paper, we propose a novel method for segmenting MS lesions that can
automatically learn features tuned for lesion segmentation and scales better to
large data sets of high-resolution 3D images than previous patch-based feature
learning approaches, which allows our model to take advantage of large data
sets. Our model is a neural network that is composed of three layers: an input
layer composed of the image voxels, a convolutional layer \cite{LeCun1998} that
extracts features from multi-modal MRIs at each voxel location, and a
deconvolutional layer \cite{zeiler2011} that uses the extracted features from
the first layer to classify each voxel of the image in a single operation. Both
layers are trained at the same time, which facilitates the learning of features
that are tuned for lesion segmentation. A key difference to the network of
Ciresan et. al \cite{Ciresan2012} is that our model is trained on the entire
images instead of multiple patches from the same image, which eliminates
redundant calculations at the overlap of neighboring patches and thereby speeds
up the training and eliminates the need to select representative patches. This
allows our model to be trained on large data sets in order to learn features
that cover the broad spectrum of lesion variability. The proposed network is
similar in architecture to a convolutional auto-encoder \cite{masci2011} but
instead of learning a lower dimensional representation of the input images
themselves, the output of your network are the predicted lesion masks. Due to
the structural similarity to convolutional auto-encoders, we will call our model
a convolutional encoder network (CEN). Traditionally, neural networks are
trained by back-propagating the sum of squared differences (SSD) of the
predicted and the expected output. However, if one class is much
overrepresented, as is the case for lesion segmentation, the algorithm would
learn to ignore the minority class completely. To overcome this problem, we
propose to use the weighted sum of sensitivity and specificity error as a new
objective function, which is suitable to deal with very unbalanced
classification problems, and we will derive the gradients of our proposed
objective function in order train the model using stochastic gradient descent.

% \paragraph{Proposed Method}
% 
% \begin{itemize}
% 
% % What it is
% 
% % Why it is great
% 
% % \item Our model is fast because we can segment an entire image in a single
% % feed-forward pass through the network. Allows to evaluate the segmentation
% % performance at training time. Allows direct maximization of the similarity
% % between predicted and ground truth segmentation during the training stage.
% 
% % Challenge
% 
% % How we overcome the challenge
% % \item The second contribution is our new proposed objective function that allows
% % NN to be applied to the voxel-wise classification in the case of very unbalanced
% % classification problems. We propose to use a weighted sum of sensitivity and
% % specificity error to better balance. We will show how convolutional neural
% % networks can be trained using the modified objective function.
% 
% \end{itemize}
